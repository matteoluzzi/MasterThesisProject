<workflow-app xmlns='uri:oozie:workflow:0.5' name='vimondSparkBatch'>
	<start to='spark-node' />

	<action name='spark-node'>
		<spark xmlns="uri:oozie:spark-action:0.1">
			<job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <master>local</master>
            <name>SparkBatch</name>
          <!--  <class>no.vimond.StorageArchitecture.App</class> -->
          <class>org.apache.oozie.example.SparkFileCopy</class>
            <jar>${nameNode}/user/${wf:user()}/${batchAppFolder}/lib/${jarName}</jar>
           <!-- <arg>${nameNode}/user/matteoremoluzzi/dataset/master/2015-07-20/13/5</arg> -->
           <arg>${nameNode}/user/${wf:user()}/${examplesRoot}/input-data/text/data.txt</arg>
            <arg>${nameNode}/user/${wf:user()}/${examplesRoot}/output-data/spark</arg>
		</spark>
		<ok to="end"/>
        <error to="fail"/>
	</action>
	 <kill name="fail">
        <message>Spark Job failed, error message[${wf:errorMessage(wf:lastErrorNode())}]</message>
    </kill>
    <end name="end"/> 
</workflow-app>
